bpi_params = {
                'batch_size': 4,
                'd_hid': 32,
                'd_model': 32,
                'dropout': 0.2163753310981849,
                'gamma_scheduler': 0.989695663239636,
                'lr': 0.0028363294173614,
                'nhead': 1,
                'nlayers': 1,
                'taxonomy_emb_size': 32,
                'taxonomy_emb_type': 'laplacian',
                'use_pe': False,
                # 'use_taxonomy': True,
                "epochs": 150,
                "bptt": 237, 
                "split_actions": True, 
                "pad": True,
                "test_split_size": 5000,
                "pos_enc_dropout": 0.01,
                "use_l2_data": False,
              }